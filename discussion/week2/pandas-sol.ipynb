{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas workbook\n",
    "\n",
    "In this notebook we will review some Pandas tricks. Examples will use the iris dataset from R.A. Fisher, 1936 as provided by the [UCI ML repo](https://archive.ics.uci.edu/dataset/53/iris)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.options.mode.copy_on_write = True\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load iris dataset\n",
    "iris = pd.read_csv(\"iris.csv\")\n",
    "iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's filter for the species being versicolor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris[iris[\"species\"] == \"versicolor\"].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris[iris[\"species\"].isin([\"versicolor\", \"setosa\"])].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise: How many observations have sepal length in the upper 50% quantile and petal width greater than 2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = np.quantile(iris[\"sepal_length\"], 0.5)\n",
    "len(iris[(iris[\"sepal_length\"] > thresh) & (iris[\"petal_width\"] > 2)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting\n",
    "\n",
    "We may want to select only a subset of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris[[\"sepal_length\", \"species\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select all columns except sepal length and species\n",
    "iris[iris.columns.difference([\"sepal_length\", \"species\"])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise: How would you select only the columns containing the word \"length\", without explicitly writing them out? (in a bigger dataset where there may be dozens of columns containing \"length\", you wouldn't want to type them all out)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(iris.columns.str.contains(\"length\"))\n",
    "print(iris.columns[iris.columns.str.contains(\"length\")])\n",
    "iris[iris.columns[iris.columns.str.contains(\"length\")]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also select columns of only certain types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select only numeric columns\n",
    "iris.select_dtypes(include=\"number\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make a new dataframe with a new column `sepal_sum`, which holds the sum of `sepal_length` and `sepal_width` for `versicolor` flowers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_vc = iris[iris[\"species\"] == \"versicolor\"]\n",
    "iris_vc[\"sepal_sum\"] = iris_vc[\"sepal_length\"] + iris_vc[\"sepal_width\"]\n",
    "iris_vc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiply every column containing \"sepal\" by 2\n",
    "iris_new = iris.copy()\n",
    "iris_new.loc[:, iris_new.columns.str.contains(\"sepal\")] *= 2\n",
    "iris_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `groupby`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.groupby(\"species\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.groupby(\"species\").apply(lambda x: x.max() - x.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise: For each species, randomly select half of the observations and compute the 0.25 quantile for each feature (i.e., sepal_length, sepal_width, petal_length, and petal_width). Hint: see `DataFrame.sample()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.groupby(\"species\").sample(25).groupby(\"species\").quantile(0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `sort_values`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.sort_values(\"petal_length\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.sort_values([\"petal_length\", \"sepal_width\"], ascending=[False, True])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise: For each species, only keep the observations with the largest 10 sepal lengths. Then, sort the rows in order of decreasing sepal length. Hint: can you do this using an `apply` with a `group_by`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.groupby(\"species\").apply(\n",
    "    lambda x: x.sort_values(\"sepal_length\", ascending=False).head(10),\n",
    "    include_groups=False,\n",
    ")\n",
    "iris.groupby(\"species\").apply(\n",
    "    lambda x: x.nlargest(10, \"sepal_length\"), include_groups=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merges (joins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make a couple dataframes to play around with merges (aka joins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "lowercase_data = pd.DataFrame(\n",
    "    dict(id=range(2, 7), lower=list(string.ascii_lowercase[1:6]))\n",
    ")\n",
    "lowercase_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uppercase_data = pd.DataFrame(\n",
    "    dict(id=range(1, 6), upper=list(string.ascii_uppercase[0:5]))\n",
    ")\n",
    "uppercase_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use these to demonstrate all four kinds of joins. In each case, the DataFrames are automatically joined on the common column `id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(lowercase_data, uppercase_data, how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(lowercase_data, uppercase_data, how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(lowercase_data, uppercase_data, how=\"right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(lowercase_data, uppercase_data, how=\"outer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lat's make a DataFrame which is rather messy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_messy = (\n",
    "    pd.concat((iris, iris.sample(n=50, replace=True)))\n",
    "    .sample(frac=1)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "iris_messy.loc[np.random.sample(iris_messy.shape[0]) < 0.1, \"species\"] = pd.NA\n",
    "iris_messy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise: clean up `iris_messy` to remove duplicate rows and rows with an NA value in `species`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up iris_messy\n",
    "iris_messy = iris_messy.drop_duplicates()\n",
    "iris_messy = iris_messy.dropna(subset=[\"species\"])\n",
    "iris_messy"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
